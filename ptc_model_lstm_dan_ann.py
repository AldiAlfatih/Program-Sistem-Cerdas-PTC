# -*- coding: utf-8 -*-
"""PTC Model LSTM dan ANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11oeYfeu5XFsjhdd5Z_pJ1eJCT_qZyTOt
"""

!pip install scikit-learn
!pip install tensorflow
!pip show tensorflow
!pip install --upgrade tensorflow
!pip install scikeras

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
from sklearn.metrics import classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, LSTM, Dense
from sklearn.model_selection import RandomizedSearchCV
from scikeras.wrappers import KerasClassifier
from scipy.stats import randint
import numpy as np

df = pd.read_csv("https://raw.githubusercontent.com/Vinzzztty/playground-data-analyst/main/Machine%20Learning%20Terapan/2.%20Sentiment%20Analysis/dataset/dataset_selada.csv")

df.head()

# print(df['Jam'].dtype)
# # MEngubah tipe data Jam
# if df['Jam'].dtype != 'object':
#     df['Jam'] = df['Jam'].astype(str)
# # mengconvert 'JAM' menjadi 'menit'
# df['Jam'] = df['Jam'].str.split('.').apply(lambda x: int(x[0]) * 60 + int(float(x[1]) * 60 / 100))

# Memilih fitur
fitur = ['temperature', 'humidity', 'TDS', 'WaterTemp']
X = df[fitur]

X.head(10)

# Menentukan jumlah cluster
n_clusters = 5

# Melakukan clustering dengan K-Means
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
df['Kategori'] = kmeans.fit_predict(X)
# kmeans = KMeans(n_clusters=n_clusters, random_state=42)
# df['Pattern'] = kmeans.fit_predict(X)

# Membagi data
X = df[fitur]
y = df['Kategori']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- Model LSTM ---

# Penskalaan data
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Transformasi data menjadi deret waktu
def create_dataset(dataset, labels, look_back=1):
    X, Y = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back), :]
        X.append(a)
        Y.append(labels.iloc[i + look_back])
    X = np.array(X)
    Y = np.array(Y)
    X = np.pad(X, ((0, len(dataset) - len(X)), (0, 0), (0, 0)), 'edge')
    Y = np.pad(Y, (0, len(dataset) - len(Y)), 'edge')
    return X, Y

look_back = 10
X_train_lstm, y_train_lstm = create_dataset(X_train_scaled, y_train, look_back)
X_test_lstm, y_test_lstm = create_dataset(X_test_scaled, y_test, look_back)

# Reshape data untuk LSTM
X_train_lstm = np.reshape(X_train_lstm, (X_train_lstm.shape[0], X_train_lstm.shape[1], X_train_lstm.shape[2]))
X_test_lstm = np.reshape(X_test_lstm, (X_test_lstm.shape[0], X_test_lstm.shape[1], X_test_lstm.shape[2]))

# Fungsi untuk membuat layer LSTM dengan dropout
def create_lstm_layer(units, dropout_rate):
    return LSTM(units=units, return_sequences=False, dropout=dropout_rate)

# Definisikan model LSTM
def create_lstm_model(units=50, dropout_rate=0.2, optimizer='adam'):
    model = Sequential()
    model.add(Input(shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))
    model.add(LSTM(units=units, return_sequences=True, dropout=dropout_rate))
    model.add(LSTM(units=units, return_sequences=False, dropout=dropout_rate))
    model.add(Dense(n_clusters, activation='softmax'))
    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
    return model

# Buat model LSTM dengan KerasClassifier
model_lstm = KerasClassifier(build_fn=create_lstm_model, verbose=0)

# Definisikan parameter distribution
param_dist_lstm = {
    'model__units': randint(30, 80),
    'batch_size': [16, 32, 64],
    'epochs': [10, 20, 30],
    'model__dropout_rate': [0.1, 0.2, 0.3],
    'model__optimizer': ['adam', 'rmsprop']
}

# Buat objek RandomizedSearchCV
random_search_lstm = RandomizedSearchCV(estimator=model_lstm, param_distributions=param_dist_lstm, n_iter=10, n_jobs=-1, cv=3)

# Latih model dengan RandomizedSearchCV
random_result_lstm = random_search_lstm.fit(X_train_lstm, y_train_lstm)

#Menampilkan Hasil
print("Best LSTM Model: %f using %s" % (random_result_lstm.best_score_, random_result_lstm.best_params_))
best_lstm_model = random_result_lstm.best_estimator_.model_
best_lstm_model.save('best_model_lstm.h5')

#Menampilkan hasil prediksi pada data latih (LSTM)
y_pred_train_lstm = np.argmax(best_lstm_model.predict(X_train_lstm), axis=1)
print("Hasil prediksi pada data latih (LSTM):")
print(y_pred_train_lstm)

#Menampilkan hasil prediksi pada data uji (LSTM)
y_pred_lstm = np.argmax(best_lstm_model.predict(X_test_lstm), axis=1)
print("Hasil prediksi pada data uji (LSTM):")
print(y_pred_lstm)

#Evaluasi model LSTM pada data uji
print("Evaluasi Model LSTM:")
print(classification_report(y_test, y_pred_lstm))

# --- Model ANN ---

def create_ann_model(neurons_1=128, neurons_2=64, activation='relu', optimizer='adam'):
    model = Sequential()
    model.add(Dense(neurons_1, activation=activation, input_dim=X_train_scaled.shape[1]))
    model.add(Dense(neurons_2, activation=activation))
    model.add(Dense(n_clusters, activation='softmax'))
    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
    return model

# Membangun model ANN dengan KerasClassifier
model_ann = KerasClassifier(build_fn=create_ann_model, verbose=0)
param_dist_ann = {
    'model__neurons_1': randint(64, 256),
    'model__neurons_2': randint(32, 128),
    'batch_size': [16, 32, 64],
    'epochs': [10, 20, 30],
    'model__activation': ['relu', 'sigmoid'],
    'model__optimizer': ['adam', 'rmsprop']
}

random_search_ann = RandomizedSearchCV(estimator=model_ann, param_distributions=param_dist_ann, n_iter=10, n_jobs=-1, cv=3)
random_result_ann = random_search_ann.fit(X_train_scaled, y_train)

#Menampilkan hasil
print("Best ANN Model: %f using %s" % (random_result_ann.best_score_, random_result_ann.best_params_))
best_ann_model = random_result_ann.best_estimator_.model_
best_ann_model.save('best_model_ann.h5')

#Menampilkan hasil prediksi pada data latih (ANN)
y_pred_train_ann = np.argmax(best_ann_model.predict(X_train_scaled), axis=1)
print("Hasil prediksi pada data latih (ANN):")
print(y_pred_train_ann)

#Menampilkan hasil prediksi pada data uji (ANN)
y_pred_ann = np.argmax(best_ann_model.predict(X_test_scaled), axis=1)
print("Hasil prediksi pada data uji (ANN):")
print(y_pred_ann)

#Evaluasi model ANN pada data uji
print("Evaluasi Model ANN:")
print(classification_report(y_test, y_pred_ann))

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred_ann)
print(cm)

import tensorflow as tf

model = tf.keras.models.load_model('best_model_ann.h5')
converter = tf.lite.TFLiteConverter.from_keras_model(model)

tfliteModel = converter.convert()

with open('best_model_ann.tflite', 'wb') as f:
    f.write(tfliteModel)